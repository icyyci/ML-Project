{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 of ML Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Inputs:\n",
    "x (list): list of words with corresponding tag in y\n",
    "y (list): list of tags with corresponding word in x\n",
    "list_of_tags (list): all tags that could be formed\n",
    "\n",
    "Output:\n",
    "tag_word_table (dictionary): dictionary with keys being tags and values being the associated words\n",
    "\n",
    "Function:\n",
    "Format data into a dictionary. Length of x and y must be the same.\n",
    "'''\n",
    "def generate_table(x, y):\n",
    "    if len(x)!=len(y):\n",
    "        print(\"ERROR: difference in length between data and tag\")\n",
    "        return None\n",
    "    \n",
    "    tag_word_table = {}\n",
    "    for tag, word in tqdm(zip(y,x)):\n",
    "        if tag in tag_word_table:\n",
    "            tag_word_table[tag].append(word)\n",
    "        else:\n",
    "            tag_word_table[tag] = [word]\n",
    "            \n",
    "    return tag_word_table\n",
    "\n",
    "'''\n",
    "Inputs:\n",
    "x (str): word to be queried\n",
    "y (str): label to be queried\n",
    "tag_word_table (dictionary): data in table form\n",
    "k (float): number of occurences #UNK# is found\n",
    "\n",
    "Output:\n",
    "probability (float): probability of generating x from y based on tag_word_table\n",
    "\n",
    "Function:\n",
    "Calculated emission probability\n",
    "'''\n",
    "def emission(x, y, tag_word_table, k = 0.5):\n",
    "    word_list = tag_word_table[y]\n",
    "    if x == \"#UNK#\":\n",
    "        emission_count = k\n",
    "    else:\n",
    "        emission_count = word_list.count(x)\n",
    "    ycount = len(word_list)\n",
    "    return emission_count / (ycount + k)\n",
    "\n",
    "'''\n",
    "Inputs:\n",
    "x (list): list of words\n",
    "\n",
    "Output:\n",
    "word_list (list): list of unique words\n",
    "\n",
    "Function:\n",
    "Generates a list of all unique words in x\n",
    "'''\n",
    "def generate_word_list(x):\n",
    "    word_list = []\n",
    "    for i in tqdm(x):\n",
    "        if i not in word_list:\n",
    "            word_list.append(i)\n",
    "    word_list.append(\"#UNK#\")\n",
    "    return word_list\n",
    "\n",
    "'''\n",
    "Inputs:\n",
    "list_x (list): list of words\n",
    "word_list (list): list of unique words\n",
    "tag_word_table (dictionary): dictionary form of the data\n",
    "\n",
    "Output:\n",
    "emission_table (numpy array): 2D numpy array with row each row representing a word and each column a tag\n",
    "\n",
    "Function:\n",
    "Generates the emission table, where each word has its emission value stored in a numpy array\n",
    "'''\n",
    "def generate_emission_table(list_x, word_list, tag_word_table):\n",
    "    # Each row is the word\n",
    "    # Each column is the tag in tag_word_table\n",
    "    emission_table = np.zeros([len(word_list), len(tag_word_table.keys())])\n",
    "    \n",
    "    tags = tag_word_table.keys()\n",
    "    \n",
    "    for ind_x,x in tqdm(enumerate(word_list)):\n",
    "        for ind_y, y in enumerate(tags):\n",
    "            em = emission(x,y,tag_word_table)\n",
    "            emission_table[ind_x,ind_y] = em\n",
    "    return emission_table\n",
    "\n",
    "'''\n",
    "Inputs:\n",
    "input_file (str): path to input file\n",
    "\n",
    "Output:\n",
    "x_list (list): list of words\n",
    "y_list (list): list of tags\n",
    "\n",
    "Function:\n",
    "Cleans the input file, as some lines have spaces within the word section. This function only takes the last\n",
    "word delimited by spaces as the tag then recombines all words delimited by space in front to form the actual\n",
    "word. Then returns the data as a list of word_list and tag_list.\n",
    "'''\n",
    "def clean(input_file):\n",
    "    inp_f = open(input_file, \"r\", encoding=\"utf-8\")\n",
    "    lines = inp_f.readlines()\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for ind, l in tqdm(enumerate(lines)):\n",
    "        words = l.split(\" \")\n",
    "        if len(words)>2:\n",
    "            tag = words[-1].strip(\"\\n\")\n",
    "            act_word = \" \".join(words[:-1])\n",
    "            x_list.append(act_word)\n",
    "            y_list.append(tag)\n",
    "        elif len(words)==2:\n",
    "            x_list.append(words[0])\n",
    "            y_list.append(words[1].strip(\"\\n\"))\n",
    "        elif len(words)==1:\n",
    "            continue\n",
    "        else:\n",
    "            print(words)\n",
    "            print(str(ind) + \"training data has no label\")\n",
    "            print(\"data is: \" + words[0])\n",
    "    return x_list, y_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "189291it [00:00, 1581659.42it/s]\n",
      "258226it [00:00, 1384587.50it/s]\n",
      "90893it [00:00, 1627412.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training data for EN\n",
    "# df_en = pd.read_csv(\"en/train\", delim_whitespace=True, names = [\"Word\", \"Tag\"])\n",
    "x_en, y_en = clean(\"en/train\")\n",
    "\n",
    "# Training data for SG\n",
    "# df_sg = pd.read_csv(\"SG/train\", delim_whitespace=True, names = [\"Word\", \"Tag\"])\n",
    "x_sg, y_sg = clean(\"SG/train\")\n",
    "\n",
    "# Training data for CN\n",
    "# df_cn = pd.read_csv(\"CN/train\", delim_whitespace=True, names = [\"Word\", \"Tag\"])\n",
    "x_cn, y_cn = clean(\"CN/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 181628/181628 [00:05<00:00, 32133.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 239667/239667 [00:23<00:00, 10315.75it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 88483/88483 [00:03<00:00, 22322.54it/s]\n"
     ]
    }
   ],
   "source": [
    "#Word list for EN\n",
    "word_list_en = generate_word_list(x_en)\n",
    "\n",
    "#Word list for SG\n",
    "word_list_sg = generate_word_list(x_sg)\n",
    "\n",
    "#Word list for CN\n",
    "word_list_cn = generate_word_list(x_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "181628it [00:00, 2718113.84it/s]\n",
      "18213it [01:51, 162.93it/s]\n",
      "239667it [00:00, 2894107.07it/s]\n",
      "42812it [03:04, 232.47it/s]\n",
      "88483it [00:00, 2163928.75it/s]\n",
      "16936it [00:21, 775.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tag word table for EN\n",
    "tag_word_table_en = generate_table(x_en, y_en)\n",
    "\n",
    "# Emission table for EN\n",
    "emission_table_en = generate_emission_table(x_en, word_list_en, tag_word_table_en)\n",
    "\n",
    "# Tag word table for SG\n",
    "tag_word_table_sg = generate_table(x_sg, y_sg)\n",
    "\n",
    "# Emission table for SG\n",
    "emission_table_sg = generate_emission_table(x_sg, word_list_sg, tag_word_table_sg)\n",
    "\n",
    "# Tag word table for CN\n",
    "tag_word_table_cn = generate_table(x_cn, y_cn)\n",
    "\n",
    "# Emission table for CN\n",
    "emission_table_cn = generate_emission_table(x_cn, word_list_cn, tag_word_table_cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find tag with highest emission and write to output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Inputs:\n",
    "x (str): word to be queried\n",
    "emission_table (numpy array): table of emission values\n",
    "word_list (list): list of unique words\n",
    "tag_word_table (dictionary): dictionary form of input data\n",
    "\n",
    "Output:\n",
    "tag (str): tag with the highest probability for the input x\n",
    "\n",
    "Function:\n",
    "Finds the tag with the highest probability given the input x and the emission table\n",
    "'''\n",
    "def find_max(x, emission_table, word_list, tag_word_table):\n",
    "    if x not in word_list:\n",
    "        x = \"#UNK#\"\n",
    "    prob_list = emission_table[word_list.index(x),:]\n",
    "    max_ind = np.argmax(prob_list)\n",
    "    return list(tag_word_table.keys())[max_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Inputs:\n",
    "input_file (str): path to input file\n",
    "output_file (str): path to output file\n",
    "emission_table (numpy array): table of emission values\n",
    "word_list (list): list of unique words\n",
    "tag_word_table (dictionary): dictionary form of input data\n",
    "\n",
    "Output:\n",
    "None\n",
    "\n",
    "Function:\n",
    "Finds the tag with the highest probability for each line in the input file and write it to the output file.\n",
    "'''\n",
    "def generate_pred(input_file, output_file, emission_table, word_list, tag_word_table):\n",
    "    inp_f = open(input_file, \"r\", encoding=\"utf-8\")\n",
    "    out_f = open(output_file, \"w\", encoding=\"utf-8\")\n",
    "    inp_lines = inp_f.readlines()\n",
    "    for x in tqdm(inp_lines):\n",
    "        inp = x.strip(\"\\n\")\n",
    "        if inp == \"\":\n",
    "            out_f.write(\"\\n\")\n",
    "            continue\n",
    "        tag = find_max(inp, emission_table, word_list, tag_word_table)\n",
    "        output = inp + \" \" + tag +\"\\n\"\n",
    "        out_f.write(output)\n",
    "    inp_f.close()\n",
    "    out_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 27225/27225 [00:02<00:00, 10328.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 36841/36841 [00:11<00:00, 3242.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 13414/13414 [00:01<00:00, 7920.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Predict for input data from en\n",
    "generate_pred(\"en/dev.in\", \"en/dev.p2.out\", emission_table_en, word_list_en, tag_word_table_en)\n",
    "\n",
    "# # Predict for input data from en\n",
    "generate_pred(\"SG/dev.in\", \"SG/dev.p2.out\", emission_table_sg, word_list_sg, tag_word_table_sg)\n",
    "\n",
    "# # Predict for input data from en\n",
    "generate_pred(\"CN/dev.in\", \"CN/dev.p2.out\", emission_table_cn, word_list_cn, tag_word_table_cn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
